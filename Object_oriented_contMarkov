'''
Work in progress . . .

'''

from __future__ import division
import random
from math import log 
from scipy.stats import rv_discrete
import scipy as sp
import numpy as np
#from scipy.stats import norm
from math import exp
import operator
import functools


# -*- coding: utf-8 -*-
"""
Created on Tue Feb 24 14:06:39 2015

@author: Andre
"""

#Goal: to make a continuous Markov chain class containing many useful methods

'''
First I want to create the class. I use the "object" argument because this
class is not drawing on methods from any other higher class. Thus, I am 
starting with a blank slate.

The function below provides the randomly drawn nucleotide that seeds the Markov 
chain simulation
'''

class contMarkov(object): #This class will contain various methods relevant to continuous time Markov chain simulations
    #I've gone ahead and insterted some default values, so I can easily run tests on the various methods
    def __init__(self, Q=[[-1.916,0.541,0.787,0.588], #Copied Q matrix from Huelsenbeck reading
                          [0.148,-1.069,0.415,0.506],
                          [0.286,0.170,-0.591,0.135],
                          [0.525,0.236,0.594,-1.355]], 
                       v=20, 
                       wTimes= None,
                       chainStates= None, 
                       stateSpace = [0,1,2,3],
                       margArray = None,
                       mpList = None,
                       allTProbs = None,
                       firstProb = None,
                       wtPDFs = None,
                       multChains = None,
                       numSims = 10):
        self.Q = Q #Q is my rate matrix (all rows sum to zero)
        self.v = v #v is my branch length (or total time)
        if wTimes is None:
            self.wTimes = []
        else:
            self.wTimes = wTimes #wTimes are the waiting times between each nucleotide substitution
        if chainStates is None:
            self.chainStates = []
        else:
            self.chainStates = chainStates #the states that comprise the Markov chain 
        self.stateSpace = stateSpace #the four possible states drawn from to make the Markov chain (numbers that correspond to the four nucleotides)
        if mpList is None:
            self.mpList = []
        else:
            self.mpList = mpList #a list of the four marginal probabilities (1/nucleotide transition) associated with the four elements in the statespace       
        if margArray is None:
            self.margArray = [[]]
        else:
            self.margArray = margArray #an array of marginal probabilities derived from Q matrix
        if allTProbs is None:
            self.allTProbs = []
        else:
            self.allTProbs = allTProbs #holds all transition probabilities except the first one (which is a marginal probability) for sequence generated by the contMarkov chain
        if firstProb is None:
            self.firstProb = []
        else:
            self.firstProb = firstProb #The (marginal) probability of the first seeded state in the contMarkov chain
        if wtPDFs is None:
            self.wtPDFs = []
        else:
            self.wtPDFs = wtPDFs#The Probability Density Function for each waiting time in the conMarkov chain simulation
        if multChains is None:
            self.multChains = [[]]
        else:
            self.multChains = multChains
        self.numSims = numSims
        self.allMargProb() #This function will calculate the marginal probabilities of the Q rate matrix using a built in function "exmp"
        self.margProbList() #Gives a list of the four marginal probabilities (1/nucleotide transition)
        #self.DiscreteSample() #Samples events from a discrete sample taking into account the probability of those events
        self.contMarkovSim() #The Markkov simulation!           
        self.conv2Letters() #Converts numbers into the nucleotides they represent.
        self.historyProb() #Calculates the probability of the specific character history generated by the Markov chain
        self.multCTMC() #Calculates and stores the results of multiple Markiov chain simulations
        
        '''
        Note to self: when calling the methods in the init statement above, it is crucial that the methods are given in an order
        such that all values necessary for that method have already been generated. Thus, for example, it is crucial that I 
        call self.DiscreteSample() before self.contMarkSim(). Also, note that only the methods have () at the end. The other self 
        statements simply refer to lists, arrays, or floats that I call in various methods.
        '''
        
        
    
    def DiscreteSample(self,xk=[0,1],pk=[0.5,0.5],numbOfTrial=1): #xk = events, pk = probalilities. Pulled this function from my previous code for this class. 
        #numbOfTrial = 1 because for the purposes of this assignment I will always want just a single output.                   
        discrete = rv_discrete(name='discrete', values=(xk,pk)) 
        sample = discrete.rvs(size=numbOfTrial)
        x = []
        x.append(sample)
        event = x[0]  
        return event  
    
    def contMarkovSim(self): #This function will run the continuous Markov simulation
        branchlength = 0 #Just setting my branchlength to the starting length
        M = self.DiscreteSample(self.stateSpace, self.mpList) #Random draw of my seed state (or nucleotide) 
        i = M[0] #If I don't take this step, then my seed state is in its own list within the chainState list
        self.firstProb = [] #stores the marginal probability of the seed
        self.firstProb.append(self.mpList[i]) #appends the marginal probability of the seed to the firstProb list
        self.wtPDFs = []
        self.wTimes = [] #Exponentially-distributed waiting times
        self.chainStates = [i] #i represents my seed state. Subsequent states will be appended to this list.      
        self.allTProbs = []
        while branchlength < self.v:           
            probs = [] #This list will contain the three probabilities associated with transition from one nucleotide to a different nucleotide. I reset this list to 0 at the beginning of each while loop.
            potentStates = [] #This is the list of potential states for the next substitution. The reason this list cannot simply be self.statespace is that it does not contain the current state.            
            ranUnif = random.uniform(0,1) #Drawing a random number between 0 and 1 so that I can find the exponentially-distributed waiting time using the equation a couple of lines down.
            lda = -(self.Q[i][i]) #defining lambda (relative rate of leaving seeded state) - notice that i is the seeded state (chosen based on marginal probabilities)
            waitTime = -(1/lda)*log(ranUnif) #finding exponentially-distributed waiting time between substitutions
            self.wTimes.append(waitTime) #append each waiting time to a list
            branchlength = sum(wt for wt in self.wTimes) #Thanks Glaucia for syntax help here. I simply add the waiting time for each successive substitution to the overall branchlength
            for rate in self.Q[i]: #In this for loop I identify the non-diagonal rates (or positive rates) in the Q matrix
                if rate >=0:                
                    prob = rate/lda #and I calculate the probabilities of each
                    probs.append(prob)
            for state in self.stateSpace: #In this for loop I identify the possible nucleotide states for the next substitution and append to a list
                if state != i:
                    potentStates.append(state)           
            for wt in self.wTimes: #In this for loop I generate the probability density function for each waiting time    
                wxPDF = -self.Q[i][i]*exp(-(-self.Q[i][i])*wt) 
                self.wtPDFs.append(wxPDF)
            i = self.DiscreteSample(potentStates, probs)
            x = potentStates.index(i)
            self.allTProbs.append(probs[x]) # Overshoots the branch length limit by 1 element (appends a new transition value after the branchlength has already reached self.v)
            self.chainStates.extend(i)
            probs[:] = []
            potentStates[:] = []
        #print ("Branchlength directly from simulation: " + str(branchlength))
        #return (("List of nucleotide substitutions: \n" + str(self.chainStates)) + "\nList of waiting times between substitutions: \n" + str(self.wTimes))
        return self.chainStates#, self.wTimes
   
    def conv2Letters(self):        
        letters = [str(cs) for cs in self.chainStates]
        letters = [s.replace('0','A') for s in letters] #Converting numbers to the nucleotides they represent. Much easier to work with numbers for everything above. Thanks to Marco for finding this syntax!
        letters = [l.replace('1','C') for l in letters]
        letters = [x.replace('2','G') for x in letters]
        letters = [p.replace('3','T') for p in letters]      
        #return ("List of nucleotide substitutions in letters: " + str(letters))       
        return letters
        
    def allMargProb(self, chainLength = 150):   
        '''
        This function will calculate the marginal probabilities of the Q rate
        matrix using a built in function "exmp"
        '''
        qArray = np.squeeze(np.asarray(self.Q))#Could not get matrix exponentiation to work, so I tried grabbing this line of code from Glaucia 
        val = sp.linalg.expm(qArray*chainLength)
        self.margArray = val
        #return ("Array of marginal probabilities derived from Q matrix: ") 
        return self.margArray
        #How do I return the description for an array?
        #Finally got this to work!!!
        
     
    def margProbList(self): #gives a list of the four marginal probabilities (1/nucleotide transition)
        self.mpList = []        
        for i in range(0,4):
            val = self.margArray[i][i]
            self.mpList.append(val)
        #return ("List of the four marginal probabilities: " + str(self.mpList))
        return self.mpList
        
    def historyProb(self):
        '''
        The goal of this function is to output the probability of the whole character history
        provided by the Markov chain simulation
        Jeremy provided the calculation pattern needed:
        P(firstNuc)*P(firstWaitingTime)*P(secNuc/firstNuc) . . . *P(1-cdf(lastWaitingTime))
        
        General strategy is to store all the relevant probabilities into a single list and then 
        multiple together all elements within that list. 
        '''
        
        # Step 1. Store the probability of the first nucleotide
        probList = []
        probList.extend(self.firstProb)       
              
        # Step 2. Store the probability of all waiting times up to the last waiting time
        probList.extend(self.wtPDFs[:-1]) #I can't include the last value, since it is the value that exceeds the desired branch length
              
        # Step 3. Store the probability for all nucleotides after the first nucleotide
        probList.extend(self.allTProbs[:-1]) #appending every element after the first nucleotide transition probability. Not including last transition probability because it corresponds to a transition occuring after the set branch length (self.v)
        
        # Step 4. Calculate the probability of the last waiting time (1-CDF(tFinal))
        lastWT = self.v - sum(self.wTimes[:-1]) #need to exclude the last wTime since it overshoots the set branchlength
        lastNuc = self.chainStates[-1]
        cdf = 1.0 - exp(-(self.Q[lastNuc][lastNuc]) * lastWT) # cdf = cumulative distribution function of the last waiting time
        lastWTProb = 1.0 - cdf
        probList.append(lastWTProb)
        # Step 5. Multiply every element in the list together
        probOfCharacterHistory = functools.reduce(operator.mul, probList, 1)
        #return ("The probability of the character history is: " + str(probOfCharacterHistory))
        return probOfCharacterHistory
       
    
    
    def optimizeBrl(self, BrlCurr=0.5, diff=0.1,thresh=0.0001): #This function is very similar to my earlier optimization function. Goal: find most likely branchlength given a starting and ending state.
      
        while diff > thresh: #This while statement limits the resolution of the optimization (and prevents getting stuck in the second while loop)
            first = self.chainStates[0]
            last = self.chainStates[-1]            
            BrlUp = BrlCurr + diff            
            BrlDown = BrlCurr - diff
            if BrlCurr < 0: 
                BrlCurr = 0 
            Lik_BrlCurr = self.allMargProb(chainLength = BrlCurr)[first][last]
            Lik_BrlUp = self.allMargProb(chainLength = BrlUp)[first][last]
            Lik_BrlDown = self.allMargProb(chainLength = BrlDown)[first][last]
            while Lik_BrlCurr < Lik_BrlUp or Lik_BrlCurr < Lik_BrlDown and Lik_BrlCurr < 1:   
                if Lik_BrlUp > Lik_BrlCurr:         
                    BrlCurr = BrlUp #value by step diff each time the "if" statement is met                
                elif Lik_BrlDown > Lik_BrlCurr: #this "while" section decreases each
                    BrlCurr = BrlDown #value by step diff each time the "if" statement is met
                BrlUp = BrlCurr + diff            
                BrlDown = BrlCurr - diff  
                if BrlCurr < 0: 
                    BrlCurr = 0 
                Lik_BrlCurr = self.allMargProb(chainLength = BrlCurr)[first][last]
                Lik_BrlUp = self.allMargProb(chainLength = BrlUp)[first][last]
                Lik_BrlDown = self.allMargProb(chainLength = BrlDown)[first][last]
                print BrlCurr, Lik_BrlCurr  #Shows that every now and then the likelihood values shoot off to infinity . . .
            #Here I want to hone the value so I reduce diff by half            
            diff *= 0.5
        #return ("Maximum likelihood branchlength for Markov chain given known starting and ending states: \n" + str(BrlCurr)) #I want to get back the Likelihood value
        return BrlCurr
    '''
    Below is parallel working code to that of the method above. 
    def MaxLikValofP(n,k,pCurr,diff): 
        
        while diff > 0.0001:
            pUp=pCurr+diff
            pDown=pCurr-diff    
            Lik_pCurr = binomialPMF(n,pCurr,k)
            Lik_pUp = binomialPMF(n,pUp,k)
            Lik_pDown = binomialPMF(n,pDown,k)
                         
            while Lik_pCurr < Lik_pUp or Lik_pCurr < Lik_pDown:
                if Lik_pUp > Lik_pCurr:         
                    pCurr = pUp #value by step diff each time the "if" statement is met                
                elif Lik_pDown > Lik_pCurr: #this "while" section decreases each
                    pCurr = pDown #value by step diff each time the "if" statement is met
                pUp=pCurr+diff
                pDown=pCurr-diff    
                Lik_pCurr = binomialPMF(n,pCurr,k)
                Lik_pUp = binomialPMF(n,pUp,k)
                Lik_pDown = binomialPMF(n,pDown,k)  
            #Here I want to hone the value so I reduce diff by half            
            diff *= 0.5
        return pCurr #I want to get back the p value
        
    maxLikValP = MaxLikValofP(3,2,0.9,0.4) #This seems to return the right value
    print maxLikValP
    '''







    def multCTMC(self): #This method will allow me to run many continuous Markov simulations and store the results as a list of lists
        for int in range(self.numSims):
            self.multChains.append(self.contMarkovSim()[0]) #borrowed Oscar's syntax here
        return self.multChains
        
            
            
            


d = contMarkov()

#print d.contMarkovSim()
#print d.conv2Letters()
#print d.allMargProb()
#print d.margProbList()
#print d.historyProb()
print d.optimizeBrl()
#print d.multCTMC()







