'''
Work in progress . . .

'''

from __future__ import division
import random
from math import log 
from scipy.stats import rv_discrete
import scipy as sp
import numpy as np
from scipy.stats import norm


# -*- coding: utf-8 -*-
"""
Created on Tue Feb 24 14:06:39 2015

@author: Andre
"""

#Goal: to make a continuous Markov chain class containing many useful methods

'''
First I want to create the class. I use the "object" argument because this
class is not drawing on methods from any other higher class. Thus, I am 
starting with a blank slate.

The function below provides the randomly drawn nucleotide that seeds the Markov 
chain simulation
'''

class contMarkov(object): #This class will contain various methods relevant to continuous time Markov chain simulations
    #I've gone ahead and insterted some default values, so I can easily run tests on the various methods
    def __init__(self, Q=[[-1.916,0.541,0.787,0.588], #Copied Q matrix from Huelsenbeck reading
                          [0.148,-1.069,0.415,0.506],
                          [0.286,0.170,-0.591,0.135],
                          [0.525,0.236,0.594,-1.355]], 
                       v=10, 
                       wTimes=[],
                       chainStates=[], 
                       stateSpace = [0,1,2,3],
                       margArray = [],
                       mpList = []):
        self.Q = Q #Q is my rate matrix (all rows sum to zero)
        self.v = v #v is my branch length (or total time)
        self.wTimes = wTimes  #wTimes are the waiting times between each nucleotide substitution
        self.chainStates = chainStates
        self.stateSpace = stateSpace
        self.margArray = margArray
        self.mpList = mpList
    
    def DiscreteSample(self,xk,pk,numbOfTrial=1): #xk = events, pk = probalilities. Pulled this function from my previous code for this class. 
        #numbOfTrial = 1 because for the purposes of this assignment I will always want just a single output.            
        discrete = rv_discrete(name='discrete', values=(xk,pk)) 
        sample = discrete.rvs(size=numbOfTrial)
        x = []
        x.append(sample)
        event = x[0]  
        return event  
    
    def contMarkovSim(self): #This function will run the continuous Markov simulation
        branchlength = 0 #Just setting my branchlength to the starting length
        i=random.choice(self.stateSpace) #Random draw of my seed state (or nucleotide)     
        self.wTimes = [] #Exponentially-distributed waiting times
        self.chainStates = [i] #i represents my seed state. Subsequent states will be appended to this list.      
        while branchlength < self.v:           
            probs = [] #This list will contain the three probabilities associated with transition from one nucleotide to a different nucleotide. I reset this list to 0 at the beginning of each while loop.
            potentStates = [] #This is the list of potential states for the next substitution. The reason this list cannot simply be self.statespace is that it does not contain the current state.            
            ranUnif = random.uniform(0,1) #Drawing a random number between 0 and 1 so that I can find the exponentially-distributed waiting time using the equation a couple of lines down.
            lda = -(self.Q[i][i]) #defining lambda - notice that i is the first randomly seeded in Huelsenbeck, "T" was arbitrarily chosen for this purpose
            waitTime = -(1/lda)*log(ranUnif) #finding exponentially-distributed waiting time between substitutions
            self.wTimes.append(waitTime)
            branchlength = sum(wt for wt in self.wTimes) #Thanks Glaucia for syntax help here. I simply add the waiting time for each successive substitution to the overall branchlength
            for rate in self.Q[i]: #In this for loop I identify the non-diagonal rates (or positive rates) in the Q matrix
                if rate >=0:                
                    prob = rate/lda #and I calculate the probabilities of each
                    probs.append(prob)
            for state in self.stateSpace: #In this forloop I identify the possible nucleotide state and append to a list
                if state != i:
                    potentStates.append(state)           
            i = self.DiscreteSample(potentStates, probs)
            self.chainStates.extend(i)
            probs[:] = []
            potentStates[:] = []
        self.chainStates = [str(cs) for cs in self.chainStates]
        self.chainStates = [s.replace('0','A') for s in self.chainStates] #Converting numbers to the nucleotides they represent. Much easier to work with numbers for everything above. Thanks to Marco for finding this syntax!
        self.chainStates = [l.replace('1','C') for l in self.chainStates]
        self.chainStates = [x.replace('2','G') for x in self.chainStates]
        self.chainStates = [p.replace('3','T') for p in self.chainStates]
        return (("List of nucleotide substitutions: " + str(self.chainStates)) + "\nList of waiting times between substitutions: " + str(self.wTimes))
    
                    
            
    def allMargProb(self, chainLength = 150):   
        qArray = np.squeeze(np.asarray(self.Q))#Could not get matrix exponentiation to work, so I tried grabbing this line of code from Glaucia 
               
        '''
        This function will calculate the marginal probabilities of the Q rate
        matrix using a built in function "exmp"
        '''
        val = sp.linalg.expm(qArray*self.v)
        self.margArray = val
        #return ("Array of marginal probabilities derived from Q matrix: ") 
        return self.margArray
        #How do I return the description for an array?
        #Finally got this to work!!!
    
    def margProbList(self): #gives a list of the four marginal probabilities (1/nucleotide transition)
        self.mpList = []        
        for i in range(0,4):
            val = d.margArray[i][i]
            self.mpList.append(val)
        return self.mpList
       
   
    
        
    


d = contMarkov()
#print d.contMarkovSim()
print d.allMargProb()
print d.margProbList()
#print d.historyProb()


'''  
def historyProb(self):
    
This function will output the probability of the whole character history
provided by the markov chain simulation

#failed attempt: firstProb = self.DiscreteSample(xk=self.stateSpace, pk=self.margProbList)
firstProb = self.DiscreteSample(self.stateSpace, self.mpList)
return firstProb
'''

